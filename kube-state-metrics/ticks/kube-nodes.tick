// destination for the normalized data
var db = 'prometheus'
var rp = 'autogen'

var true_value = 1
var false_value = 0
var unknown_value = -1

var prefix = 'kube_node'
var measurement = prefix + '_'
var destination = prefix + 's'

// This should be equal to / shorter than the scraper period (eg 10s), to avoid including a window with multiple time occurrences of the same point.
// (I've seen occasional errors when attempt "equal to", so we're using "shorter than" for now.)
var cycle_time = 5s

// Normalize metric into measurement
stream
    |from()
    |where(lambda: strHasPrefix("__name__", measurement))
    |window()
        .period(cycle_time)
        .every(cycle_time)
    |groupBy('node')
    @groupConsolidateTrueFalseUnknown()
        .measurement('kube_node_status_disk_pressure')
        .tag('condition')
        .trueValue(true_value)
        .falseValue(false_value)
        .unknownValue(unknown_value)
    @groupConsolidateTrueFalseUnknown()
        .measurement('kube_node_status_memory_pressure')
        .tag('condition')
        .trueValue(true_value)
        .falseValue(false_value)
        .unknownValue(unknown_value)
    @groupConsolidateTrueFalseUnknown()
        .measurement('kube_node_status_out_of_disk')
        .tag('condition')
        .trueValue(true_value)
        .falseValue(false_value)
        .unknownValue(unknown_value)
    @groupConsolidateTrueFalseUnknown()
        .measurement('kube_node_status_ready')
        .tag('condition')
        .trueValue(true_value)
        .falseValue(false_value)
        .unknownValue(unknown_value)
    @groupJoinToSinglePoint()
        .stripPrefix(measurement)
        .dropTag('__name__')
        .ignoreValueFrom('kube_node_info')
        .ignoreValueFrom('kube_node_labels')
    |kapacitorLoopback()
        .database(db)
        .retentionPolicy(rp)
        .measurement(destination)

